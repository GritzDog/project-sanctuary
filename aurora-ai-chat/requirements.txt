llama-cpp-python==0.2.20
fastapi==0.104.1
uvicorn==0.24.0
websockets==12.0
pydantic==2.5.0
aiofiles==23.2.1
numpy==1.24.3
torch==2.1.0
transformers==4.35.0
python-multipart==0.0.6
